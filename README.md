# ğŸš• Taxi Driver - FastAPI Reinforcement Learning

Nouvelle implÃ©mentation de l'API d'apprentissage par renforcement utilisant FastAPI, avec une architecture extensible pour intÃ©grer facilement de nouveaux algorithmes.

## ğŸ¯ Objectif

Reproduire la logique de l'API Python originale en se concentrant sur **SARSA** tout en gardant une architecture qui permet d'intÃ©grer facilement d'autres algorithmes (Q-Learning, Monte Carlo, etc.) dans le futur.

## ğŸ—ï¸ Architecture

```
taxi-driver/
â”œâ”€â”€ main.py                 # Point d'entrÃ©e FastAPI
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ schemas/           # ModÃ¨les Pydantic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ common.py      # ParamÃ¨tres communs
â”‚   â”‚   â””â”€â”€ sarsa.py       # ParamÃ¨tres SARSA
â”‚   â””â”€â”€ services/          # Logique mÃ©tier
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base_agent.py  # Classe de base pour les agents
â”‚       â””â”€â”€ sarsa.py       # ImplÃ©mentation SARSA
â”œâ”€â”€ assets/                # Images gÃ©nÃ©rÃ©es
â””â”€â”€ models/                # ModÃ¨les sauvegardÃ©s
```

## ğŸš€ Installation et lancement

### 1. Installation des dÃ©pendances

```bash
cd taxi-driver
pip install -r requirements.txt
```

### 2. Lancement de l'API

```bash
python main.py
```

L'API sera disponible sur `http://localhost:8000`

### 3. Documentation interactive

- **Swagger UI** : `http://localhost:8000/docs`
- **ReDoc** : `http://localhost:8000/redoc`

## ğŸ“Š Endpoints disponibles

### SARSA

- **POST** `/sarsa` - EntraÃ®nement SARSA avec paramÃ¨tres personnalisÃ©s ou optimisÃ©s

### Utilitaires

- **GET** `/` - Page d'accueil
- **GET** `/health` - VÃ©rification de l'Ã©tat de l'API

## ğŸ® Utilisation

### Exemple d'appel SARSA avec paramÃ¨tres optimisÃ©s

```bash
curl -X POST "http://localhost:8000/sarsa" \
     -H "Content-Type: application/json" \
     -d '{
       "mode": "optimized",
       "test_episodes": 250
     }'
```

### Exemple d'appel SARSA avec paramÃ¨tres personnalisÃ©s

```bash
curl -X POST "http://localhost:8000/sarsa" \
     -H "Content-Type: application/json" \
     -d '{
       "mode": "user",
       "alpha": 0.1,
       "gamma": 0.99,
       "eps": 1.0,
       "eps_decay": 0.995,
       "eps_min": 0.01,
       "training_runs": 1000,
       "maxStepsPerEpisode": 200,
       "test_episodes": 100
     }'
```

## ğŸ”§ ParamÃ¨tres SARSA

### Mode "optimized"

Utilise les paramÃ¨tres validÃ©s expÃ©rimentalement :

- **alpha**: 0.12
- **gamma**: 0.99
- **eps**: 1.0
- **eps_decay**: 0.9995
- **eps_min**: 0.001
- **training_runs**: 6000
- **test_episodes**: 250

### Mode "user"

Permet de personnaliser tous les paramÃ¨tres selon vos besoins.

## ğŸ“ˆ FonctionnalitÃ©s

### âœ… ImplÃ©mentÃ©

- **SARSA** avec mÃ©triques Ã©tendues
- **ParamÃ¨tres optimisÃ©s** validÃ©s expÃ©rimentalement
- **GÃ©nÃ©ration de graphiques** (6 graphiques diffÃ©rents)
- **MÃ©triques systÃ¨me** (CPU, RAM)
- **Comparaison avec Brute Force**
- **Sauvegarde des modÃ¨les**
- **Architecture extensible** pour futurs algorithmes

### ğŸ”® ExtensibilitÃ© future

L'architecture permet d'ajouter facilement :

- **Q-Learning**
- **Monte Carlo**
- **Deep Q-Learning**
- **K-Learning**
- **Autres algorithmes de RL**

## ğŸ¯ RÃ©sultats attendus

Avec les paramÃ¨tres optimisÃ©s, SARSA devrait atteindre :

- **Taux de succÃ¨s** : ~100%
- **Nombre moyen de pas** : ~13.1
- **AmÃ©lioration vs Brute Force** : >80%

## ğŸ“ Structure des rÃ©sultats

Chaque exÃ©cution gÃ©nÃ¨re :

- **Images** : 6 graphiques de performance
- **ModÃ¨le** : Fichier pickle avec la Q-table
- **Rapport JSON** : Statistiques dÃ©taillÃ©es
- **Run ID unique** : Pour identifier chaque exÃ©cution

## ğŸ”„ DiffÃ©rences avec l'API originale

### âœ… AmÃ©liorations

- **FastAPI** au lieu de Flask
- **Architecture modulaire** et extensible
- **Validation automatique** des paramÃ¨tres
- **Documentation interactive** intÃ©grÃ©e
- **Gestion d'erreurs** amÃ©liorÃ©e

### ğŸ¯ Conservation

- **Logique SARSA** identique
- **ParamÃ¨tres optimisÃ©s** conservÃ©s
- **MÃ©triques et graphiques** identiques
- **Performance** Ã©quivalente

## ğŸš€ Prochaines Ã©tapes

1. **Tests unitaires** et d'intÃ©gration
2. **IntÃ©gration d'autres algorithmes** (Q-Learning, Monte Carlo)
3. **Interface web** pour visualiser les rÃ©sultats
4. **Base de donnÃ©es** pour sauvegarder l'historique
5. **Authentification** et gestion des utilisateurs
